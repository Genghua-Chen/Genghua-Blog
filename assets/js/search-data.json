{
  
    
        "post0": {
            "title": "Genghua Chen Resume",
            "content": "Education . Feitian College at Middletown, Middletown, NY Expected June 2022 . Bachelor of Data Science . Stratford High School, Houston, TX May 2018 . PROJECTS . Bank Marketing Deposit Classification January 2021 - February 2021 . Conducted data cleaning, converted categorical to numeric and selected statistical significance features to improve model performance and performed more than 93% area under the ROC curve score for the model predicting power . Tested multiple classification models such as Random Forest, Decision Tree, K-nearest neighbors, Extra-Trees and Gradient Boosting . World happiness  June 2020 - August 2020 . Business data analytics . Imported structure table, CSV and  Excel files into Tableau and designed and built a data visualization dashboard using two years historical data to rank most happiness and unhappiness . Built a heat map, scatter plots and pie chart to display six key factors: income, freedom, trust in government, life expectancy, social support and generosity . Presented PowerPoint presentation to clearly communicated world happiness result . Experience . The Epoch Times, New York, NY  July 2019 - September 2019 . Advertising Sales Assistant . Monitored subscribers and emerging trends in Google Analytics and effectively defined target market . Collaborated with leadership to prepared a list of targeted companies for e-blast . Raised brand awareness via e-blast to increase number of subscribers revenue and profit . New Tang Dynasty Television, Houston, TX March 2017 - November 2017 . Video Editor . Created an initial proposed storyboard draft of more than 30 videos to presented to stakeholders’ and received approvals before production to digitally alter video . Analyzed written scripts and raw materials to create a timeline based on valuable scenes and contribution . Continuously discovered and implemented new editing technologies and industry’s best practices to maximize efficiency . Kate spade outlets, Woodbury, NY November 2019 - January 2020 . Sales Associate . Results-oriented, effectively cross-selling products, and increase 15% sales revenue and 35% customer service by leveraging my communication, bilingual literacy and by analyzing foot traffic at the plaza . Assessed customers’ needs, introduced promotions and products, for order management and improved engagement and maintained customer relations .",
            "url": "https://genghua-chen.github.io/Genghua-Blog/2021/03/28/Genghua-Chen-Resume.html",
            "relUrl": "/2021/03/28/Genghua-Chen-Resume.html",
            "date": " • Mar 28, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "0.The Dataset",
            "content": "Age . Job . Marital Status . Education . Default: Having a previously broken credit . Balance: Balance of the individual. . Housing: Any housing loan . Loan: Any personal Loan . Contact: Contact communication type . Month: Last month of contact . Day: The day of the contacted . Duration: Talk time on last call(Unit: Sec) . Campaign: The number of contacts reaching the customer during the current campaign . Pdays: The number of days since the previous campaign, if reached (-1 if it was never reached before) . Previous: The number of contacts that reached the customer before this campaign . Poutcome: Previous campaign success, failure or failure . Deposit: Client subscribed a term deposit . 1.Exploratory data analysis . import numpy as np import pandas as pd import copy # conda install -c https://conda.anaconda.org/plotly plotly import matplotlib.pyplot as plt import matplotlib.style as style import numpy as np import pandas as pd import plotly.express as px import seaborn as sns from scipy import stats import warnings warnings.filterwarnings(&quot;ignore&quot;) import seaborn as sns import matplotlib.pyplot as plt from matplotlib import pyplot from datetime import date from sklearn.preprocessing import StandardScaler from sklearn.preprocessing import Normalizer from sklearn.preprocessing import MinMaxScaler from numpy import array from numpy import argmax from sklearn.preprocessing import LabelEncoder from sklearn.preprocessing import OneHotEncoder from sklearn.model_selection import train_test_split from collections import defaultdict from sklearn.linear_model import LinearRegression from sklearn.ensemble import RandomForestClassifier from sklearn import metrics from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, roc_curve from sklearn.metrics import accuracy_score from sklearn.tree import DecisionTreeClassifier from sklearn.tree import DecisionTreeRegressor from sklearn.ensemble.forest import ExtraTreesClassifier from sklearn.ensemble.gradient_boosting import GradientBoostingClassifier from sklearn.metrics import confusion_matrix,auc,roc_curve # from lightgbm import LGBMClassifier from sklearn.neighbors import KNeighborsClassifier import os for dirname, _, filenames in os.walk(&#39;/kaggle/input&#39;): for filename in filenames: print(os.path.join(dirname, filename)) . df = pd.read_csv(&#39;/Users/genghua/Desktop/Data/bank.csv&#39;) . df.head(5) . age job marital education default balance housing loan contact day month duration campaign pdays previous poutcome deposit . 0 | 59 | admin. | married | secondary | no | 2343 | yes | no | unknown | 5 | may | 1042 | 1 | -1 | 0 | unknown | yes | . 1 | 56 | admin. | married | secondary | no | 45 | no | no | unknown | 5 | may | 1467 | 1 | -1 | 0 | unknown | yes | . 2 | 41 | technician | married | secondary | no | 1270 | yes | no | unknown | 5 | may | 1389 | 1 | -1 | 0 | unknown | yes | . 3 | 55 | services | married | secondary | no | 2476 | yes | no | unknown | 5 | may | 579 | 1 | -1 | 0 | unknown | yes | . 4 | 54 | admin. | married | tertiary | no | 184 | no | no | unknown | 5 | may | 673 | 2 | -1 | 0 | unknown | yes | . df.shape . (11162, 17) . df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 11162 entries, 0 to 11161 Data columns (total 17 columns): age 11162 non-null int64 job 11162 non-null object marital 11162 non-null object education 11162 non-null object default 11162 non-null object balance 11162 non-null int64 housing 11162 non-null object loan 11162 non-null object contact 11162 non-null object day 11162 non-null int64 month 11162 non-null object duration 11162 non-null int64 campaign 11162 non-null int64 pdays 11162 non-null int64 previous 11162 non-null int64 poutcome 11162 non-null object deposit 11162 non-null object dtypes: int64(7), object(10) memory usage: 1.4+ MB . df.isnull().sum() . age 0 job 0 marital 0 education 0 default 0 balance 0 housing 0 loan 0 contact 0 day 0 month 0 duration 0 campaign 0 pdays 0 previous 0 poutcome 0 deposit 0 dtype: int64 . df.describe() . age balance day duration campaign pdays previous . count | 11162.000000 | 11162.000000 | 11162.000000 | 11162.000000 | 11162.000000 | 11162.000000 | 11162.000000 | . mean | 41.231948 | 1528.538524 | 15.658036 | 371.993818 | 2.508421 | 51.330407 | 0.832557 | . std | 11.913369 | 3225.413326 | 8.420740 | 347.128386 | 2.722077 | 108.758282 | 2.292007 | . min | 18.000000 | -6847.000000 | 1.000000 | 2.000000 | 1.000000 | -1.000000 | 0.000000 | . 25% | 32.000000 | 122.000000 | 8.000000 | 138.000000 | 1.000000 | -1.000000 | 0.000000 | . 50% | 39.000000 | 550.000000 | 15.000000 | 255.000000 | 2.000000 | -1.000000 | 0.000000 | . 75% | 49.000000 | 1708.000000 | 22.000000 | 496.000000 | 3.000000 | 20.750000 | 1.000000 | . max | 95.000000 | 81204.000000 | 31.000000 | 3881.000000 | 63.000000 | 854.000000 | 58.000000 | . df.describe(include = &#39;object&#39;) . job marital education default housing loan contact month poutcome deposit . count | 11162 | 11162 | 11162 | 11162 | 11162 | 11162 | 11162 | 11162 | 11162 | 11162 | . unique | 12 | 3 | 4 | 2 | 2 | 2 | 3 | 12 | 4 | 2 | . top | management | married | secondary | no | no | no | cellular | may | unknown | no | . freq | 2566 | 6351 | 5476 | 10994 | 5881 | 9702 | 8042 | 2824 | 8326 | 5873 | . df[&#39;deposit&#39;].value_counts() . no 5873 yes 5289 Name: deposit, dtype: int64 . # ndf = df.loc[(df[&#39;poutcome&#39;] != &quot;unknown&quot;) &amp; (df[&#39;poutcome&#39;] != &quot;other&quot;)] # print(df.shape, ndf.shape) . counts = df.deposit.value_counts() normal = counts[0] Churn = counts[1] perc_normal = (normal/(normal+Churn))*100 perc_Churn = (Churn/(normal+Churn))*100 print(&#39;There were {} non-Churn ({:.3f}%) and {} Churn ({:.3f}%).&#39;.format(normal, perc_normal, Churn, perc_Churn)) . There were 5873 non-Churn (52.616%) and 5289 Churn (47.384%). . df . age job marital education default balance housing loan contact day month duration campaign pdays previous poutcome deposit . 0 | 59 | admin. | married | secondary | no | 2343 | yes | no | unknown | 5 | may | 1042 | 1 | -1 | 0 | unknown | yes | . 1 | 56 | admin. | married | secondary | no | 45 | no | no | unknown | 5 | may | 1467 | 1 | -1 | 0 | unknown | yes | . 2 | 41 | technician | married | secondary | no | 1270 | yes | no | unknown | 5 | may | 1389 | 1 | -1 | 0 | unknown | yes | . 3 | 55 | services | married | secondary | no | 2476 | yes | no | unknown | 5 | may | 579 | 1 | -1 | 0 | unknown | yes | . 4 | 54 | admin. | married | tertiary | no | 184 | no | no | unknown | 5 | may | 673 | 2 | -1 | 0 | unknown | yes | . ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 11157 | 33 | blue-collar | single | primary | no | 1 | yes | no | cellular | 20 | apr | 257 | 1 | -1 | 0 | unknown | no | . 11158 | 39 | services | married | secondary | no | 733 | no | no | unknown | 16 | jun | 83 | 4 | -1 | 0 | unknown | no | . 11159 | 32 | technician | single | secondary | no | 29 | no | no | cellular | 19 | aug | 156 | 2 | -1 | 0 | unknown | no | . 11160 | 43 | technician | married | secondary | no | 0 | no | yes | cellular | 8 | may | 9 | 2 | 172 | 5 | failure | no | . 11161 | 34 | technician | married | secondary | no | 0 | no | no | cellular | 9 | jul | 628 | 1 | -1 | 0 | unknown | no | . 11162 rows × 17 columns . # df.job.value_counts()/ len(df.job)*100 # df.marital.value_counts()/ len(df.marital)*100 # df.education.value_counts()/ len(df.education)*100 # df.default.value_counts()/ len(df.default)*100 # df.loan.value_counts()/ len(df.loan)*100 # df.contact.value_counts()/ len(df.contact)*100 # df.month.value_counts()/ len(df.month)*100 # df.poutcome.value_counts()/ len(df.duration)*100 # df.deposit.value_counts()/ len(df.duration)*100 . df.hist(figsize=(14,14)) . array([[&lt;matplotlib.axes._subplots.AxesSubplot object at 0x7f9e63ce8d50&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x7f9e63b61bd0&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x7f9e647dbb50&gt;], [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x7f9e640a2e90&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x7f9e63c13c10&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x7f9e64358f10&gt;], [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x7f9e63e47790&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x7f9e63f6ca90&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x7f9e63f88550&gt;]], dtype=object) . bal_his = df.loc[(df[&#39;balance&#39;] &lt; 20000)] bal_his[&#39;balance&#39;].hist(figsize=(10,10), bins = 40) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f9e63a97b10&gt; . f, axes = plt.subplots(nrows=2, ncols=3, figsize=(25,15)) sns.boxplot(x=&quot;deposit&quot;, y=&quot;age&quot;, data=df, ax=axes[0,0]) sns.boxplot(x=&quot;deposit&quot;, y=&quot;balance&quot;, data=df, ax=axes[0,1]) sns.boxplot(x=&quot;deposit&quot;, y=&quot;day&quot;, data=df, ax=axes[0,2]) sns.boxplot(x=&quot;deposit&quot;, y=&quot;duration&quot;, data=df, ax=axes[1,0]) sns.boxplot(x=&quot;deposit&quot;, y=&quot;campaign&quot;, data=df, ax=axes[1,1]) sns.boxplot(x=&quot;deposit&quot;, y=&quot;pdays&quot;, data=df, ax=axes[1,2]) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f9e611b8750&gt; . plt.figure(figsize=[12,14]) features=[&quot;marital&quot;, &quot;education&quot;, &quot;contact&quot;, &quot;default&quot;, &quot;housing&quot;, &quot;loan&quot;, &quot;poutcome&quot;] n=1 for f in features: plt.subplot(4,2,n) sns.countplot(x=f, hue=&#39;deposit&#39;, edgecolor=&quot;black&quot;, alpha=0.7, data=df) sns.despine() plt.title(&quot;Countplot of {} by deposit&quot;.format(f)) n=n+1 plt.tight_layout() plt.show() plt.figure(figsize=[14,4]) sns.countplot(x=&#39;job&#39;, hue=&#39;deposit&#39;,edgecolor=&quot;black&quot;, alpha=0.7, data=df) sns.despine() plt.title(&quot;Countplot of job by deposit&quot;) plt.show() . sns.set_style(&#39;whitegrid&#39;) plt.subplots(figsize = (10,10)) ## Plotting heatmap. Generate a mask for the upper triangle (taken from seaborn example gallery) mask = np.zeros_like(df.corr(), dtype=np.bool) mask[np.triu_indices_from(mask)] = True ax = sns.heatmap(df.corr(), cmap=sns.diverging_palette(20, 220, n=200), annot=True, mask=mask, center = 0, ); plt.title(&quot;Heatmap of Data Set&quot;, fontsize = 25); ax.get_ylim() # output: (6.5, 0.5) ax.set_ylim(7,0) . (7, 0) . 2.Converting Categorical Columns to Numeric Columns . # df=pd.concat([df,pd.get_dummies(df[columns])],axis=1) # df=df.drop(df[&#39;job&#39;,&#39;marital&#39;,&#39;education&#39;,&#39;default&#39;,&#39;housing&#39;,&#39;loan&#39;,&#39;contact&#39;,&#39;month&#39;,&#39;day&#39;,&#39;poutcome&#39;],axis=1) df = df.replace(to_replace =&quot;yes&quot;, value =1) df = df.replace(to_replace =&quot;no&quot;, value =0) . df.dtypes . age int64 job object marital object education object default int64 balance int64 housing int64 loan int64 contact object day int64 month object duration int64 campaign int64 pdays int64 previous int64 poutcome object deposit int64 dtype: object . df . age job marital education default balance housing loan contact day month duration campaign pdays previous poutcome deposit . 0 | 59 | admin. | married | secondary | 0 | 2343 | 1 | 0 | unknown | 5 | may | 1042 | 1 | -1 | 0 | unknown | 1 | . 1 | 56 | admin. | married | secondary | 0 | 45 | 0 | 0 | unknown | 5 | may | 1467 | 1 | -1 | 0 | unknown | 1 | . 2 | 41 | technician | married | secondary | 0 | 1270 | 1 | 0 | unknown | 5 | may | 1389 | 1 | -1 | 0 | unknown | 1 | . 3 | 55 | services | married | secondary | 0 | 2476 | 1 | 0 | unknown | 5 | may | 579 | 1 | -1 | 0 | unknown | 1 | . 4 | 54 | admin. | married | tertiary | 0 | 184 | 0 | 0 | unknown | 5 | may | 673 | 2 | -1 | 0 | unknown | 1 | . ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 11157 | 33 | blue-collar | single | primary | 0 | 1 | 1 | 0 | cellular | 20 | apr | 257 | 1 | -1 | 0 | unknown | 0 | . 11158 | 39 | services | married | secondary | 0 | 733 | 0 | 0 | unknown | 16 | jun | 83 | 4 | -1 | 0 | unknown | 0 | . 11159 | 32 | technician | single | secondary | 0 | 29 | 0 | 0 | cellular | 19 | aug | 156 | 2 | -1 | 0 | unknown | 0 | . 11160 | 43 | technician | married | secondary | 0 | 0 | 0 | 1 | cellular | 8 | may | 9 | 2 | 172 | 5 | failure | 0 | . 11161 | 34 | technician | married | secondary | 0 | 0 | 0 | 0 | cellular | 9 | jul | 628 | 1 | -1 | 0 | unknown | 0 | . 11162 rows × 17 columns . sns.set_style(&#39;whitegrid&#39;) plt.subplots(figsize = (10,10)) ## Plotting heatmap. Generate a mask for the upper triangle (taken from seaborn example gallery) mask = np.zeros_like(df.corr(), dtype=np.bool) mask[np.triu_indices_from(mask)] = True ax = sns.heatmap(df.corr(), cmap=sns.diverging_palette(20, 220, n=200), annot=True, mask=mask, center = 0, ); plt.title(&quot;Heatmap of New Data Set&quot;, fontsize = 25); ax.get_ylim() # output: (10.5, 0.5) ax.set_ylim(11,0) . (11, 0) . cols=np.array(df.columns[df.dtypes != object]) df.dtypes # cols # for i in df_train.columns: # if i not in cols: # df_train[i]=df_train[i].map(str) # df_train.drop(columns=cols,inplace=True) # df_train.head(5) . age int64 job object marital object education object default int64 balance int64 housing int64 loan int64 contact object day int64 month object duration int64 campaign int64 pdays int64 previous int64 poutcome object deposit int64 dtype: object . # # random.seed(2) # cols=np.array(df.columns[df.dtypes != object]) # d = defaultdict(LabelEncoder) # df_train = df_train.apply(lambda x: d[x.name].fit_transform(x)) # df_train[cols] = df[cols] # df_train.head(5) . df_train = df.copy() df_train = pd.get_dummies(df_train, columns = [&#39;job&#39;, &#39;marital&#39;, &#39;education&#39;, &#39;contact&#39;, &#39;month&#39;, &#39;poutcome&#39;]) df_train df_train.dtypes . age int64 default int64 balance int64 housing int64 loan int64 day int64 duration int64 campaign int64 pdays int64 previous int64 deposit int64 job_admin. uint8 job_blue-collar uint8 job_entrepreneur uint8 job_housemaid uint8 job_management uint8 job_retired uint8 job_self-employed uint8 job_services uint8 job_student uint8 job_technician uint8 job_unemployed uint8 job_unknown uint8 marital_divorced uint8 marital_married uint8 marital_single uint8 education_primary uint8 education_secondary uint8 education_tertiary uint8 education_unknown uint8 contact_cellular uint8 contact_telephone uint8 contact_unknown uint8 month_apr uint8 month_aug uint8 month_dec uint8 month_feb uint8 month_jan uint8 month_jul uint8 month_jun uint8 month_mar uint8 month_may uint8 month_nov uint8 month_oct uint8 month_sep uint8 poutcome_failure uint8 poutcome_other uint8 poutcome_success uint8 poutcome_unknown uint8 dtype: object . # plt.subplots(figsize = (20,20)) # ## Plotting heatmap. Generate a mask for the upper triangle (taken from seaborn example gallery) # mask = np.zeros_like(df_train.corr(), dtype=np.bool) # mask[np.triu_indices_from(mask)] = True # ax = sns.heatmap(df_train.corr(), cmap=sns.diverging_palette(20, 220, n=200), annot=True, mask=mask, center = 0, ); # plt.title(&quot;Heatmap of All Data Set&quot;, fontsize = 25); # ax.get_ylim() # output: (16.5, 0.5) # ax.set_ylim(17,0) . 3.Feature Selection . corr = df_train.corr() a = corr.sort_values([&quot;deposit&quot;], ascending = False, inplace = True) print(corr.deposit) . deposit 1.000000 duration 0.451919 poutcome_success 0.286642 contact_cellular 0.223252 pdays 0.151593 previous 0.139867 month_mar 0.135438 month_oct 0.133783 month_sep 0.126901 job_retired 0.103827 job_student 0.099953 marital_single 0.094632 education_tertiary 0.094598 month_apr 0.090975 month_dec 0.086964 balance 0.081129 month_feb 0.051710 poutcome_other 0.044059 job_management 0.036301 age 0.034901 job_unemployed 0.033487 poutcome_failure 0.020714 contact_telephone 0.016420 education_unknown 0.014355 marital_divorced 0.005228 job_unknown 0.001889 job_admin. -0.000610 job_self-employed -0.004707 job_technician -0.011557 month_aug -0.016621 month_jun -0.018982 month_jan -0.021803 job_housemaid -0.024155 month_nov -0.028278 job_entrepreneur -0.034443 default -0.040680 job_services -0.044531 month_jul -0.047368 education_secondary -0.051952 day -0.056326 education_primary -0.063002 marital_married -0.092157 job_blue-collar -0.100840 loan -0.110580 campaign -0.128081 month_may -0.170507 housing -0.203888 poutcome_unknown -0.230470 contact_unknown -0.256136 Name: deposit, dtype: float64 . c = corr[[&#39;deposit&#39;]] c d = corr[&#39;deposit&#39;].loc[(corr[&#39;deposit&#39;].abs() &gt; 0.1)] print(d) type(d) list(d.index) . deposit 1.000000 duration 0.451919 poutcome_success 0.286642 contact_cellular 0.223252 pdays 0.151593 previous 0.139867 month_mar 0.135438 month_oct 0.133783 month_sep 0.126901 job_retired 0.103827 job_blue-collar -0.100840 loan -0.110580 campaign -0.128081 month_may -0.170507 housing -0.203888 poutcome_unknown -0.230470 contact_unknown -0.256136 Name: deposit, dtype: float64 . [&#39;deposit&#39;, &#39;duration&#39;, &#39;poutcome_success&#39;, &#39;contact_cellular&#39;, &#39;pdays&#39;, &#39;previous&#39;, &#39;month_mar&#39;, &#39;month_oct&#39;, &#39;month_sep&#39;, &#39;job_retired&#39;, &#39;job_blue-collar&#39;, &#39;loan&#39;, &#39;campaign&#39;, &#39;month_may&#39;, &#39;housing&#39;, &#39;poutcome_unknown&#39;, &#39;contact_unknown&#39;] . df_g1 = df_train[[&#39;deposit&#39;, &#39;duration&#39;, &#39;poutcome_success&#39;, &#39;contact_cellular&#39;, &#39;pdays&#39;, &#39;previous&#39;, &#39;month_mar&#39;, &#39;month_oct&#39;, &#39;month_sep&#39;, &#39;job_retired&#39;, &#39;loan&#39;, &#39;campaign&#39;, &#39;month_may&#39;, &#39;housing&#39;, &#39;poutcome_unknown&#39;, &#39;contact_unknown&#39;]] . df_g2 = df_train[list(d.index)] df_g2 . deposit duration poutcome_success contact_cellular pdays previous month_mar month_oct month_sep job_retired job_blue-collar loan campaign month_may housing poutcome_unknown contact_unknown . 0 | 1 | 1042 | 0 | 0 | -1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | 1 | 1 | 1 | . 1 | 1 | 1467 | 0 | 0 | -1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | 0 | 1 | 1 | . 2 | 1 | 1389 | 0 | 0 | -1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | 1 | 1 | 1 | . 3 | 1 | 579 | 0 | 0 | -1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | 1 | 1 | 1 | . 4 | 1 | 673 | 0 | 0 | -1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 2 | 1 | 0 | 1 | 1 | . ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 11157 | 0 | 257 | 0 | 1 | -1 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 1 | 0 | 1 | 1 | 0 | . 11158 | 0 | 83 | 0 | 0 | -1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 4 | 0 | 0 | 1 | 1 | . 11159 | 0 | 156 | 0 | 1 | -1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 2 | 0 | 0 | 1 | 0 | . 11160 | 0 | 9 | 0 | 1 | 172 | 5 | 0 | 0 | 0 | 0 | 0 | 1 | 2 | 1 | 0 | 0 | 0 | . 11161 | 0 | 628 | 0 | 1 | -1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 1 | 0 | . 11162 rows × 17 columns . sns.set_style(&#39;whitegrid&#39;) plt.subplots(figsize = (15,15)) ## Plotting heatmap. Generate a mask for the upper triangle (taken from seaborn example gallery) mask = np.zeros_like(df_g2.corr(), dtype=np.bool) mask[np.triu_indices_from(mask)] = True ax = sns.heatmap(df_g2.corr(), cmap=sns.diverging_palette(20, 220, n=200), annot=True, mask=mask, center = 0, ); plt.title(&quot;Heatmap of New Data Set&quot;, fontsize = 25); ax.get_ylim() # output: (10.5, 0.5) ax.set_ylim(17,0) . (17, 0) . . x = df_train.duration y = df_train.deposit plt.scatter(x, y) model = LinearRegression(fit_intercept=True) model.fit(x[:, np.newaxis], y) xfit = np.linspace(0, 4000, 1000) yfit = model.predict(xfit[:, np.newaxis]) plt.scatter(x, y) plt.plot(xfit, yfit) . [&lt;matplotlib.lines.Line2D at 0x7f9e625ec810&gt;] . train, test = train_test_split(df_train, test_size=0.3, random_state=42, shuffle=True) print(train.shape, test.shape) . (7813, 49) (3349, 49) . train.describe() . age default balance housing loan day duration campaign pdays previous ... month_jun month_mar month_may month_nov month_oct month_sep poutcome_failure poutcome_other poutcome_success poutcome_unknown . count | 7813.000000 | 7813.000000 | 7813.000000 | 7813.000000 | 7813.000000 | 7813.000000 | 7813.000000 | 7813.000000 | 7813.000000 | 7813.000000 | ... | 7813.000000 | 7813.000000 | 7813.000000 | 7813.000000 | 7813.000000 | 7813.000000 | 7813.000000 | 7813.000000 | 7813.000000 | 7813.000000 | . mean | 41.237169 | 0.014335 | 1536.787278 | 0.467938 | 0.133495 | 15.605273 | 369.986433 | 2.499552 | 49.952643 | 0.802253 | ... | 0.109177 | 0.024318 | 0.252400 | 0.087290 | 0.036094 | 0.029566 | 0.108665 | 0.045565 | 0.094714 | 0.751056 | . std | 11.850243 | 0.118876 | 3215.999050 | 0.499003 | 0.340131 | 8.419817 | 345.882463 | 2.722798 | 107.826919 | 2.135139 | ... | 0.311881 | 0.154046 | 0.434417 | 0.282278 | 0.186535 | 0.169398 | 0.311238 | 0.208553 | 0.292838 | 0.432429 | . min | 18.000000 | 0.000000 | -3058.000000 | 0.000000 | 0.000000 | 1.000000 | 2.000000 | 1.000000 | -1.000000 | 0.000000 | ... | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | . 25% | 32.000000 | 0.000000 | 124.000000 | 0.000000 | 0.000000 | 8.000000 | 138.000000 | 1.000000 | -1.000000 | 0.000000 | ... | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 1.000000 | . 50% | 39.000000 | 0.000000 | 553.000000 | 0.000000 | 0.000000 | 15.000000 | 253.000000 | 2.000000 | -1.000000 | 0.000000 | ... | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 1.000000 | . 75% | 49.000000 | 0.000000 | 1730.000000 | 1.000000 | 0.000000 | 21.000000 | 492.000000 | 3.000000 | -1.000000 | 0.000000 | ... | 0.000000 | 0.000000 | 1.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 1.000000 | . max | 95.000000 | 1.000000 | 81204.000000 | 1.000000 | 1.000000 | 31.000000 | 3881.000000 | 63.000000 | 854.000000 | 41.000000 | ... | 1.000000 | 1.000000 | 1.000000 | 1.000000 | 1.000000 | 1.000000 | 1.000000 | 1.000000 | 1.000000 | 1.000000 | . 8 rows × 49 columns . test.describe() . age default balance housing loan day duration campaign pdays previous ... month_jun month_mar month_may month_nov month_oct month_sep poutcome_failure poutcome_other poutcome_success poutcome_unknown . count | 3349.000000 | 3349.000000 | 3349.000000 | 3349.000000 | 3349.000000 | 3349.000000 | 3349.000000 | 3349.000000 | 3349.000000 | 3349.000000 | ... | 3349.000000 | 3349.000000 | 3349.000000 | 3349.000000 | 3349.000000 | 3349.000000 | 3349.000000 | 3349.000000 | 3349.000000 | 3349.000000 | . mean | 41.219767 | 0.016721 | 1509.294715 | 0.485219 | 0.124515 | 15.781129 | 376.676918 | 2.529113 | 54.544640 | 0.903255 | ... | 0.110182 | 0.025679 | 0.254404 | 0.077934 | 0.032846 | 0.026277 | 0.113168 | 0.054046 | 0.098835 | 0.733950 | . std | 12.061128 | 0.128245 | 3247.670769 | 0.499856 | 0.330217 | 8.422863 | 350.024934 | 2.720690 | 110.850401 | 2.620721 | ... | 0.313163 | 0.158200 | 0.435591 | 0.268107 | 0.178259 | 0.159980 | 0.316845 | 0.226142 | 0.298486 | 0.441956 | . min | 18.000000 | 0.000000 | -6847.000000 | 0.000000 | 0.000000 | 1.000000 | 4.000000 | 1.000000 | -1.000000 | 0.000000 | ... | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | . 25% | 32.000000 | 0.000000 | 118.000000 | 0.000000 | 0.000000 | 8.000000 | 138.000000 | 1.000000 | -1.000000 | 0.000000 | ... | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | . 50% | 38.000000 | 0.000000 | 546.000000 | 0.000000 | 0.000000 | 15.000000 | 259.000000 | 2.000000 | -1.000000 | 0.000000 | ... | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 1.000000 | . 75% | 49.000000 | 0.000000 | 1644.000000 | 1.000000 | 0.000000 | 22.000000 | 503.000000 | 3.000000 | 85.000000 | 1.000000 | ... | 0.000000 | 0.000000 | 1.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 1.000000 | . max | 93.000000 | 1.000000 | 81204.000000 | 1.000000 | 1.000000 | 31.000000 | 3284.000000 | 43.000000 | 842.000000 | 58.000000 | ... | 1.000000 | 1.000000 | 1.000000 | 1.000000 | 1.000000 | 1.000000 | 1.000000 | 1.000000 | 1.000000 | 1.000000 | . 8 rows × 49 columns . def Definedata(): # define dataset X=df_train.drop(columns=[&#39;deposit&#39;]).values y=df_train[&#39;deposit&#39;].values return X, y . def Models_NO(models, graph): import pdb model = models X, y = Definedata() X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 25) model.fit(X_train,y_train) y_pred = model.predict(X_test) y_total = model.predict(X) print(y_train.sum()) if graph: train_matrix = pd.crosstab(y_train, model.predict(X_train), rownames=[&#39;Actual&#39;], colnames=[&#39;Predicted&#39;]) test_matrix = pd.crosstab(y_test, model.predict(X_test), rownames=[&#39;Actual&#39;], colnames=[&#39;Predicted&#39;]) matrix = pd.crosstab(y, model.predict(X), rownames=[&#39;Actual&#39;], colnames=[&#39;Predicted&#39;]) f,(ax1,ax2,ax3) = plt.subplots(1,3,sharey=True, figsize=(15, 2)) g1 = sns.heatmap(train_matrix, annot=True, fmt=&quot;.1f&quot;, cbar=False,annot_kws={&quot;size&quot;: 18},ax=ax1) g1.set_title(title) g1.set_ylabel(&#39;Total Deposit = {}&#39;.format(y_train.sum()), fontsize=14, rotation=90) g1.set_xlabel(&#39;Accuracy for TrainSet: {}&#39;.format(accuracy_score(model.predict(X_train), y_train))) g1.set_xticklabels([&#39;Deposit&#39;,&#39;No Deposit&#39;],fontsize=12) g2 = sns.heatmap(test_matrix, annot=True, fmt=&quot;.1f&quot;,cbar=False,annot_kws={&quot;size&quot;: 18},ax=ax2) g2.set_title(title) g2.set_ylabel(&#39;Total Deposit = {}&#39;.format(y_test.sum()), fontsize=14, rotation=90) g2.set_xlabel(&#39;Accuracy for TestSet: {}&#39;.format(accuracy_score(y_pred, y_test))) g2.set_xticklabels([&#39;Deposit&#39;,&#39;No Deposit&#39;],fontsize=12) g3 = sns.heatmap(matrix, annot=True, fmt=&quot;.1f&quot;,cbar=False,annot_kws={&quot;size&quot;: 18},ax=ax3) g3.set_title(title) g3.set_ylabel(&#39;Total Deposit = {}&#39;.format( y.sum()), fontsize=14, rotation=90) g3.set_xlabel(&#39;Accuracy for TotalSet: {}&#39;.format(accuracy_score(y_total, y))) g3.set_xticklabels([&#39;Deposit&#39;,&#39;No Deposit&#39;],fontsize=12) g3.set_ylim(2,0) # g3.set_xlim(1) plt.show() # print (&quot;&quot;) # print (&quot;Classification Report: &quot;) # print (classification_report(y, y_total)) #pdb.set_trace() else: print(&quot; t tError Table&quot;) print(&#39;Mean Absolute Error : &#39;, metrics.mean_absolute_error(y_test, (y_pred))) print(&#39;Mean Squared Error : &#39;, metrics.mean_squared_error(y_test, (y_pred) )) print(&#39;Root Mean Squared Error : &#39;, np.sqrt(metrics.mean_squared_error(y_test, (y_pred) ))) print(&#39;Accuracy on Traing set : &#39;, model.score(X_train,y_train)) print(&#39;Accuracy on Testing set : &#39;, model.score(X_test,y_test)) print(&#39;Accuracy on Testing set : &#39;, accuracy_score(y_pred, y_test)) # print(&#39;Accuracy on Testing set : &#39;, accuracy_score(y_total, y)) print(&#39;AUC score :&#39;, roc_auc_score(y, y_total)*100,&#39;%&#39;) #pdb.set_trace() return y_total, y . title = &#39;Decision Tree Regressor&#39; y_predict, y_test = Models_NO(DecisionTreeRegressor(), True) . 3691 . y_predicted, y_actual = Models_NO(DecisionTreeRegressor(), False) fpr, tpr, thresholds = roc_curve(y_actual, y_predicted) roc_auc = auc(fpr, tpr) plt.title(&#39;Receiver Operating Characteristic&#39;) plt.plot(fpr, tpr, &#39;b&#39;,label=&#39;AUC = %0.3f&#39;% roc_auc) plt.legend(loc=&#39;lower right&#39;) plt.plot([0,1],[0,1],&#39;r--&#39;) plt.xlim([-0.1,1.0]) plt.ylim([-0.1,1.01]) plt.ylabel(&#39;True Positive Rate&#39;) plt.xlabel(&#39;False Positive Rate&#39;) plt.show() . 3691 Error Table Mean Absolute Error : 0.22096148103911614 Mean Squared Error : 0.22096148103911614 Root Mean Squared Error : 0.4700654008104789 Accuracy on Traing set : 1.0 Accuracy on Testing set : 0.11430550323827116 Accuracy on Testing set : 0.7790385189608838 AUC score : 93.34370539306866 % . title = &#39;Random Forest Classifier&#39; y_predict, y_test = Models_NO(RandomForestClassifier(), True) . 3691 . y_predicted, y_actual = Models_NO(RandomForestClassifier(), False) fpr, tpr, thresholds = roc_curve(y_actual, y_predicted) roc_auc = auc(fpr, tpr) plt.title(&#39;Receiver Operating Characteristic&#39;) plt.plot(fpr, tpr, &#39;b&#39;,label=&#39;AUC = %0.3f&#39;% roc_auc) plt.legend(loc=&#39;lower right&#39;) plt.plot([0,1],[0,1],&#39;r--&#39;) plt.xlim([-0.1,1.0]) plt.ylim([-0.1,1.01]) plt.ylabel(&#39;True Positive Rate&#39;) plt.xlabel(&#39;False Positive Rate&#39;) plt.show() . 3691 Error Table Mean Absolute Error : 0.19408778739922364 Mean Squared Error : 0.19408778739922364 Root Mean Squared Error : 0.44055395515103896 Accuracy on Traing set : 0.9923204914885447 Accuracy on Testing set : 0.8059122126007764 Accuracy on Testing set : 0.8059122126007764 AUC score : 93.58595083937288 % . title = &#39;ExtraTreesClassifier&#39; y_predict, y_test = Models_NO(ExtraTreesClassifier(), True) . 3691 . y_predicted, y_actual = Models_NO(ExtraTreesClassifier(), False) fpr, tpr, thresholds = roc_curve(y_actual, y_predicted) roc_auc = auc(fpr, tpr) plt.title(&#39;Receiver Operating Characteristic&#39;) plt.plot(fpr, tpr, &#39;b&#39;,label=&#39;AUC = %0.3f&#39;% roc_auc) plt.legend(loc=&#39;lower right&#39;) plt.plot([0,1],[0,1],&#39;r--&#39;) plt.xlim([-0.1,1.0]) plt.ylim([-0.1,1.01]) plt.ylabel(&#39;True Positive Rate&#39;) plt.xlabel(&#39;False Positive Rate&#39;) plt.show() . 3691 Error Table Mean Absolute Error : 0.21379516273514482 Mean Squared Error : 0.21379516273514482 Root Mean Squared Error : 0.4623798900635113 Accuracy on Traing set : 1.0 Accuracy on Testing set : 0.7862048372648551 Accuracy on Testing set : 0.7862048372648551 AUC score : 93.50666822868895 % . title = &#39;GradientBoostingClassifier&#39; y_predict, y_test = Models_NO(GradientBoostingClassifier(), True) . 3691 . y_predicted, y_actual = Models_NO(GradientBoostingClassifier(), False) fpr, tpr, thresholds = roc_curve(y_actual, y_predicted) roc_auc = auc(fpr, tpr) plt.title(&#39;Receiver Operating Characteristic&#39;) plt.plot(fpr, tpr, &#39;b&#39;,label=&#39;AUC = %0.3f&#39;% roc_auc) plt.legend(loc=&#39;lower right&#39;) plt.plot([0,1],[0,1],&#39;r--&#39;) plt.xlim([-0.1,1.0]) plt.ylim([-0.1,1.01]) plt.ylabel(&#39;True Positive Rate&#39;) plt.xlabel(&#39;False Positive Rate&#39;) plt.show() . 3691 Error Table Mean Absolute Error : 0.16363093460734549 Mean Squared Error : 0.16363093460734549 Root Mean Squared Error : 0.4045132069628203 Accuracy on Traing set : 0.8662485600921541 Accuracy on Testing set : 0.8363690653926545 Accuracy on Testing set : 0.8363690653926545 AUC score : 85.79682468427883 % . title = &#39;KNeighborsClassifier&#39; y_predict, y_test = Models_NO(KNeighborsClassifier(), True) . 3691 . y_predicted, y_actual = Models_NO(KNeighborsClassifier(), False) fpr, tpr, thresholds = roc_curve(y_actual, y_predicted) roc_auc = auc(fpr, tpr) plt.title(&#39;Receiver Operating Characteristic&#39;) plt.plot(fpr, tpr, &#39;b&#39;,label=&#39;AUC = %0.3f&#39;% roc_auc) plt.legend(loc=&#39;lower right&#39;) plt.plot([0,1],[0,1],&#39;r--&#39;) plt.xlim([-0.1,1.0]) plt.ylim([-0.1,1.01]) plt.ylabel(&#39;True Positive Rate&#39;) plt.xlabel(&#39;False Positive Rate&#39;) plt.show() . 3691 Error Table Mean Absolute Error : 0.2639593908629442 Mean Squared Error : 0.2639593908629442 Root Mean Squared Error : 0.5137697839139085 Accuracy on Traing set : 0.820427492640471 Accuracy on Testing set : 0.7360406091370558 Accuracy on Testing set : 0.7360406091370558 AUC score : 79.3873856141418 % .",
            "url": "https://genghua-chen.github.io/Genghua-Blog/2021/02/20/Data-Analysis-Bank-Marketing.html",
            "relUrl": "/2021/02/20/Data-Analysis-Bank-Marketing.html",
            "date": " • Feb 20, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://genghua-chen.github.io/Genghua-Blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://genghua-chen.github.io/Genghua-Blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "",
          "url": "https://genghua-chen.github.io/Genghua-Blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://genghua-chen.github.io/Genghua-Blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}